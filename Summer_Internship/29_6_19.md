# Day 22 of Summer Internship

*Date: June 29th, 2019*

Being a Saturday, many of my colleagues were on leave. So I had time to work. I sat down and wrote the code to update the existing model and dictionary. This code is meant to run on a lot of files, which were wrongly identified by the original model. This is essentially the code that implements the real "learning" part of the "machine learning" concept. After the user has identified a number of mails which were wrongly identified, this code will be executed with those mails as input. For the purpose of updating the model, I used [partial_fit](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.partial_fit) method because that was the only one I could find with an ability to update the existing model. 

There was another issue which took considerable time to solve. The dictionary is stored in file after serialization with json. Ans so, it has to be serialized with json, thus when loaded, the dictionary is of type json. But, originally, it was an object of class Counter from the package collections. So how could we merge these two incompatible types. I wanted it to load the original dictionary, make a new one from the incorrectly classified mails, and then merge these two adding new words and incrementing the count of previous words. Searching around, I found the [update](https://docs.python.org/3.5/library/collections.html#collections.Counter.update) method of the Counter class. You can pass the string and its count and if not already present, it will add that string with count or if already present, it will add the given count to previous count. Pretty neat! So I passed my json values one by one to the counter object's update method and my work was done.

Now after finishing this whole part, I ran the code to update the model and dictionary. It took around 6 mins for the code to read all 2853 spam mails, update the dictionary and then the model. One restriction was that since I had build the original model with 3000 words in the dictionary, now I can't extend my dictionary beyond 3000 words. If I want to extend my dictionary, I have to build a new model.

Now it was the time to put it all to test. I passed all the 2853 spam mails to the software and here is the result:

	Total mails: 2853
	Classified as spam: 2849
	Classified as ham: 4
	Accuracy: 99.85%
	Time consumed: 3min 47sec

Similar to last time, I was skeptical of this one too. I would need to test it with ham mails to be sure.

While waiting for the ham mails, I thought that I should write the documentation of the software. I had earlier started this work, using doxygen. The fact that doxygen wasn't originally meant for python was a bit of problem. Though they have recently added support for python, but they still don't support [special commands](http://www.doxygen.nl/manual/commands.html#cmd_intro) in [docstrings](https://www.python.org/dev/peps/pep-0257/#what-is-a-docstring) as per their [official documentation](http://www.doxygen.nl/manual/docblocks.html#pythonblocks). So I rather used "#" for using the special commands. But even that wasn't working. I wanted to use the special commands like [@author](http://www.doxygen.nl/manual/commands.html#cmdauthor), [@date](http://www.doxygen.nl/manual/commands.html#cmddate), [@bugs](http://www.doxygen.nl/manual/commands.html#cmdbug) and other such commands. But doxygen just wasn't picking them.

I searched the internet, but couldn't find any clear solution. I will try again tomorrow with a new zeal. And if you are wondering why I am focusing so much on the documentation, well here is why:

![](https://b2bstorytelling.files.wordpress.com/2012/12/consultant_cartoon.jpg)
