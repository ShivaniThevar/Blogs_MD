# Day 3 of Summer Internship

*Date: June 6th, 2019*

Today was a rather interesting day. Right after entering the office (I was late though) I went to meet my head (as I had planned [yesterday](https://hacksd.wordpress.com/2019/06/05/day-2-of-summer-internship/) and he had planned a very fascinating project for me.

A **Spam-Email Filter using Machine Learning!!!**

Nebero provides mail-servers to its clients. So its better if they have their own spam-detection service. And what better way to built it than using Machine Learning.

So my head sent me this [link](https://medium.com/analytics-vidhya/building-a-spam-filter-from-scratch-using-machine-learning-fc58b178ea56) to learn more about the project. This link used GNU Octave to implement the project.
I read that post and found more articles about building a spam-filter using ML. A [node.js implementation](https://www.booleanworld.com/building-spam-filter-using-machine-learning/) and a [python one](https://appliedmachinelearning.blog/2017/01/23/email-spam-filter-python-scikit-learn/).

To summarize the basic idea behind the spam-filter, we can think of how we classify a text message as a happy one or a not so happy one.
We read the text, and then take useful keywords from it. If the keywords in the message are "happy", "smile", "good", "awesome", "yay" then there is 90% chance that the text is happy text. On the other hand, if the keywords are "sad", "low", "stressed", "tired" then you probably wanna gift a chocolate to the sender.
So very similar to this, we look for keywords in the mail to classify it as spam or not-spam (also called ham by many). But unlike the happy message example above, we rarely have a set of keywords that clearly mean the message is a spam. And that's where machine learning comes!!!

The job of ML here is to continuously build that "set of keywords" (called dictionary) and assign them "weights" (called feature) which is the probability of the mail being spam if it contains that keyword. And to calculate that probability we will use the [Naive Bayes Theorem](https://www.machinelearningplus.com/predictive-modeling/how-naive-bayes-algorithm-works-with-example-and-full-code/).

We will follow the given steps to develop our project:

1. **Prepare Data**: To train and test the model, we will prepare data, i.e mails, to be utilized by the software. This has further parts which I will discuss in another post.

1. **Generate Dictionary**: We will read the preprocessed data and bring out keywords that are frequently present in the mails and note their respective frequency.

1. **Generate Feature**: This step will assign the weights to each word in the dictionary.

1. **Generate the ML Model**: When we have the required dictionary and feature, we will use Naive Bayes Theorem to predict whether the given mail is a spam or not. Then given the correctness of the result, we will adjust the dictionary and features.

1. **Test the ML Model**: After the model has "learned" from the previous step, we will test it with new data that it has never seen. Again, based on the correctness we will tweak the model and ask it to learn again (similar to what happens to students in tests).

The moment I heard that I had to use ML in the project, a thought crossed my mind that I should use Python as the tool. And surely enough, in the python implementation I mentioned above, I found the way, tools and code to use as a base for my project. Another reason why I chose python was because it has the [scikit-learn library](https://scikit-learn.org/stable/index.html) which will be a great help in building this project.

So the workflow that I planned today was:

1. **Build prototype**: I will follow the instructions given [here](https://appliedmachinelearning.blog/2017/01/23/email-spam-filter-python-scikit-learn/) to build the prototype. This will be almost same as the one that they have built.

2. **Add pre-processor**: After successfully testing the prototype with the processed data, I will add the pre-processor that will read all the incoming mails, pre-processes them (i.e removes stop words, URLs, numbers, etc. and performs lemmatization) and then passes it on to the prototype.

3. **Extensive testing**: Increasing the size of dictionary and optimizing weights of words.

After this, we should have a basic functioning spam filter with us that could be deployed. Then we could further enhance its features with:

4. **User inputs**: Before putting any mail in the spam folder, ask the user. If the user input matches with the spam filter, then it increases the weights of the spam words in that particular email, else the weights are decreased by some percentage.

5. **Block/report spammers**: After a predefined number of spam mails from an address, it will be warned. If it continues to send spam mails, it will be blocked.

So now that I have got my project and have my work-plan ready, I am totally pumped to start working on it.
